{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Libraries"
      ],
      "metadata": {
        "id": "XLUDDrh0bEsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import logging #for logs\n",
        "import sys #to aid logging"
      ],
      "metadata": {
        "id": "Z93pmfNqbDih"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "logging module"
      ],
      "metadata": {
        "id": "yeALWQSTbXQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# logging setup for debunggin and tracking\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    stream=sys.stdout,\n",
        "    force=True\n",
        ")"
      ],
      "metadata": {
        "id": "abJblNRnbZfs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "file configuration"
      ],
      "metadata": {
        "id": "s78dYHcgbcMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# configuration\n",
        "\n",
        "#inputs\n",
        "LEADS_FILE = \"crm_leads.csv\"\n",
        "TRANSACTIONS_FILE = \"transactions.txt\"\n",
        "WEB_ACTIVITY_FILE = \"web_activity.json\"\n",
        "#outputs\n",
        "C360_FILE = \"customer_360.parquet\"\n",
        "REJECTED_LOG_FILE = \"rejected_transactions.log\""
      ],
      "metadata": {
        "id": "RN8yrgkubjOh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Engineering"
      ],
      "metadata": {
        "id": "6RnLnlehbu6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.extracting data files\n"
      ],
      "metadata": {
        "id": "tFYc2M8WfuxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.extracting data files\n",
        "\n",
        "def extract_data():\n",
        "    \"\"\"Extract all data sources.\"\"\"\n",
        "    logging.info(\"starting the data extraction\")\n",
        "\n",
        "    leads = pd.read_csv(LEADS_FILE)\n",
        "    transactions = pd.read_csv(TRANSACTIONS_FILE, sep='|')\n",
        "    web_activity = pd.read_json(WEB_ACTIVITY_FILE, lines=True)\n",
        "\n",
        "    return leads, transactions, web_activity"
      ],
      "metadata": {
        "id": "gX9M9DoKfdNI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Transformations   (cleaning and deduplications)"
      ],
      "metadata": {
        "id": "mYv08gOvf1MB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Transformations   (cleaning and deduplications)\n",
        "\n",
        "def clean_leads(df):   #crm_leads.csv\n",
        "    \"\"\"Clean and deduplicate leads.\"\"\"\n",
        "    df = df.copy()\n",
        "    df['full_name'] = df['full_name'].str.title()  #formatting case in names\n",
        "    df['email'] = df['email'].str.lower().str.strip() # case in email\n",
        "    df['creation_date'] = pd.to_datetime(df['creation_date']) #datatime formatting\n",
        "\n",
        "    # Deduplicate - keeping most recent record per email\n",
        "    df = df.sort_values('creation_date', ascending=False)\n",
        "    df = df.drop_duplicates(subset='email', keep='first')\n",
        "\n",
        "    df = df.sort_values('lead_id').reset_index(drop=True)\n",
        "\n",
        "    logging.info(f\"cleaned leads\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def clean_transactions(df):   #transactions.txt\n",
        "    \"\"\"Clean and validate transactions.\"\"\"\n",
        "    logging.info(\"cleaning transactions data\")\n",
        "\n",
        "    df = df.copy()\n",
        "    df['amount'] = pd.to_numeric(df['amount'], errors='coerce') #forttminh strings and int\n",
        "\n",
        "    valid_mask = df['amount'].notna() & (df['amount'] > 0) #filterting bussines case i.e negative values\n",
        "\n",
        "    valid = df[valid_mask].copy()  #reson for rejections\n",
        "    rejected = df[~valid_mask].copy()\n",
        "\n",
        "    rejected['reason'] = rejected['amount'].apply(\n",
        "        lambda x: 'Invalid or missing amount' if pd.isna(x) else f'Non-positive amount ({x})'\n",
        "    )\n",
        "\n",
        "    logging.info(f\"valid transactions: {len(valid)}, rejected: {len(rejected)}\")\n",
        "    return valid, rejected\n",
        "\n",
        "\n",
        "def clean_web_activity(df):   #web acitivity.jason\n",
        "    \"\"\"Clean and validate web activity.\"\"\"\n",
        "    logging.info(\"cleaning web activity data\")\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    df = df[df['user_uuid'].notna() & (df['user_uuid'] != '')] #removing null user uuid rows\n",
        "\n",
        "    df['page_view_count'] = pd.to_numeric(df['page_view_count'], errors='coerce') #formatiing string int\n",
        "    df['last_seen_ts'] = pd.to_datetime(df['last_seen_ts'])\n",
        "\n",
        "    logging.info(f\"cleaned web activity, rejeted: 2 due to null user uuids\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def create_email_uuid_mapping(leads_df, transactions_df, web_activity_df):\n",
        "\n",
        "# To maintain referential and analytical integrity, I implemented a simple positional mapping between\n",
        "# user_uuid and email so that lead information could be represented in the final dataset.\n",
        "# However, since no explicit identity map was provided to link crm_leads.csv with either transactions.txt or\n",
        "#  web_activity.json, this mapping serves only as a placeholder to simulate a complete join for demonstration purposes.\n",
        "\n",
        "    logging.info(\"simple mapping as a place holder\")\n",
        "\n",
        "    trans_uuids = transactions_df['user_uuid'].unique()\n",
        "    web_uuids = web_activity_df['user_uuid'].unique()\n",
        "    all_uuids = []\n",
        "    seen = set()\n",
        "    for uuid in list(trans_uuids) + list(web_uuids):\n",
        "        if uuid not in seen:\n",
        "            all_uuids.append(uuid)\n",
        "            seen.add(uuid)\n",
        "\n",
        "    emails = leads_df['email'].tolist()\n",
        "    mapping_size = min(len(emails), len(all_uuids))\n",
        "\n",
        "    mapping_df = pd.DataFrame({\n",
        "        'position': range(mapping_size),\n",
        "        'email': emails[:mapping_size],\n",
        "        'user_uuid': all_uuids[:mapping_size]\n",
        "    })\n",
        "\n",
        "    return mapping_df[['email', 'user_uuid']]\n",
        "\n",
        "\n",
        "def aggregate_transactions(df): #aggregating of transactions.txt\n",
        "    \"\"\"Aggregate transactions by user with status breakdown\"\"\"\n",
        "\n",
        "    status_counts = df.groupby(['user_uuid', 'status']).size().unstack(fill_value=0)\n",
        "    status_counts.columns = [f'{col.lower()}_transactions' for col in status_counts.columns]\n",
        "\n",
        "    status_amounts = df.groupby(['user_uuid', 'status'])['amount'].sum().unstack(fill_value=0)\n",
        "    status_amounts.columns = [f'{col.lower()}_amount' for col in status_amounts.columns]\n",
        "\n",
        "    overall = df.groupby('user_uuid').agg(\n",
        "        total_sales=('amount', 'sum'),\n",
        "        total_transactions=('transaction_id', 'count'),\n",
        "        transaction_ids=('transaction_id', lambda x: ','.join(x))\n",
        "    )\n",
        "\n",
        "    summary = overall.join(status_counts).join(status_amounts).reset_index()\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "def aggregate_web_activity(df):  #aggregating of web_activity.jason\n",
        "    \"\"\"Aggregate web activity by user.\"\"\"\n",
        "    summary = df.groupby('user_uuid').agg(\n",
        "        total_page_views=('page_view_count', 'sum'),\n",
        "        last_activity=('last_seen_ts', 'max')\n",
        "    ).reset_index()\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "def build_customer_360(leads_df, trans_summary, web_summary, mapping_df):\n",
        "  #building the finaly paquet with all leads, transaction, and summary with mapping\n",
        "    #outer merge so as to not loose any uuids or lead id\n",
        "    logging.info(\"building customer 360\")\n",
        "\n",
        "    c360 = mapping_df.merge(leads_df, on='email', how='outer')\n",
        "    c360 = c360.merge(trans_summary, on='user_uuid', how='outer')\n",
        "    c360 = c360.merge(web_summary, on='user_uuid', how='outer')\n",
        "\n",
        "\n",
        "    numeric_cols = ['total_sales', 'total_transactions', 'completed_transactions',\n",
        "                'pending_transactions','completed_amount', 'pending_amount',\n",
        "                'total_page_views']\n",
        "    for col in numeric_cols:\n",
        "        if col in c360.columns:\n",
        "            c360[col] = c360[col].fillna(0) #filling null values due to mismatch dimensions\n",
        "\n",
        "    count_cols = ['total_transactions', 'completed_transactions', 'total_page_views','pending_transactions']\n",
        "    for col in count_cols:\n",
        "        if col in c360.columns:\n",
        "            c360[col] = c360[col].astype(int) #conversion\n",
        "\n",
        "\n",
        "    c360 = c360.sort_values('lead_id').reset_index(drop=True)\n",
        "\n",
        "    cols = c360.columns.tolist()\n",
        "    if 'transaction_ids' in cols:\n",
        "        cols.remove('transaction_ids')\n",
        "        lead_id_index = cols.index('lead_id')\n",
        "        cols.insert(lead_id_index + 1, 'transaction_ids')\n",
        "        c360 = c360[cols]\n",
        "\n",
        "    return c360"
      ],
      "metadata": {
        "id": "prJUvR5ufh_2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Loading outputs"
      ],
      "metadata": {
        "id": "N3omnEwSf_9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Loading all\n",
        "\n",
        "def save_customer_360(df):\n",
        "    #saing cusotmer360 parquet\n",
        "    logging.info(f\"Saving Customer 360 to {C360_FILE}\")\n",
        "    df.to_parquet(C360_FILE, index=False, engine='pyarrow')\n",
        "    logging.info(\"Customer 360 saved successfully\")\n",
        "\n",
        "\n",
        "def save_rejected_log(df):\n",
        "#sacing the rejection log\n",
        "    if df.empty:\n",
        "        return\n",
        "    with open(REJECTED_LOG_FILE, 'w') as f:\n",
        "        f.write(\"transaction_id|status|amount|reason\\n\")\n",
        "        for _, row in df.iterrows():\n",
        "            f.write(f\"{row['transaction_id']}|{row['status']}|{row['amount']}|{row['reason']}\\n\")\n",
        "\n",
        "    logging.info(\"Rejected transactions log saved\")\n"
      ],
      "metadata": {
        "id": "IOHozywvyNBJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Main"
      ],
      "metadata": {
        "id": "GCiT6v-SgH1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Main\n",
        "\n",
        "def main():\n",
        "#runs all functions Entire ETL pipline\n",
        "    logging.info(\"starting ETL Pipeline\")\n",
        "\n",
        "    try:\n",
        "        # 1. xtract\n",
        "        leads, transactions, web_activity = extract_data()\n",
        "\n",
        "        # 2. transform\n",
        "        # Clean individual datasets\n",
        "        leads_clean = clean_leads(leads)\n",
        "        trans_valid, trans_rejected = clean_transactions(transactions)\n",
        "        web_clean = clean_web_activity(web_activity)\n",
        "\n",
        "        # Create email-UUID mapping (positional)\n",
        "        mapping = create_email_uuid_mapping(leads_clean, trans_valid, web_clean)\n",
        "\n",
        "        # Aggregate data\n",
        "        trans_summary = aggregate_transactions(trans_valid)\n",
        "        web_summary = aggregate_web_activity(web_clean)\n",
        "\n",
        "        # build parquet\n",
        "        customer_360 = build_customer_360(\n",
        "            leads_clean,\n",
        "            trans_summary,\n",
        "            web_summary,\n",
        "            mapping\n",
        "        )\n",
        "\n",
        "        # 3. laod\n",
        "        save_customer_360(customer_360)\n",
        "        save_rejected_log(trans_rejected)\n",
        "\n",
        "        logging.info(\"ETL pipelie completed successfully\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Pipeline failed: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwxkVA-7fnCx",
        "outputId": "c8c9274d-5acc-4020-9e5e-873fc1fc6943"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-11 20:21:06,722 - INFO - starting ETL Pipeline\n",
            "2025-11-11 20:21:06,724 - INFO - starting the data extraction\n",
            "2025-11-11 20:21:06,782 - INFO - cleaned leads\n",
            "2025-11-11 20:21:06,783 - INFO - cleaning transactions data\n",
            "2025-11-11 20:21:06,792 - INFO - valid transactions: 6, rejected: 2\n",
            "2025-11-11 20:21:06,794 - INFO - cleaning web activity data\n",
            "2025-11-11 20:21:06,802 - INFO - cleaned web activity, rejeted: 2 due to null user uuids\n",
            "2025-11-11 20:21:06,803 - INFO - simple mapping as a place holder\n",
            "2025-11-11 20:21:06,886 - INFO - building customer 360\n",
            "2025-11-11 20:21:06,931 - INFO - Saving Customer 360 to customer_360.parquet\n",
            "2025-11-11 20:21:07,081 - INFO - Customer 360 saved successfully\n",
            "2025-11-11 20:21:07,084 - INFO - Rejected transactions log saved\n",
            "2025-11-11 20:21:07,085 - INFO - ETL pipelie completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Output 360"
      ],
      "metadata": {
        "id": "Z1S2Gf_ngKeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#customer360 parquet\n",
        "customer360 = pd.read_parquet(\"/content/customer_360.parquet\")\n",
        "print(customer360)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSgRejH-HbBX",
        "outputId": "7c708d39-5275-433c-ae73-fd4caf6a8dc8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       email                             user_uuid lead_id  \\\n",
            "0         jane.doe@other.com  e4f5d3a1-8b0c-47e2-a1f3-d9c4e0b5a6f7  L-1002   \n",
            "1         bob.brown@test.net  d2c3b4a5-6e7f-48d9-a2e1-c0b9d8a7e6f5  L-1004   \n",
            "2     john.smith@example.com  99999999-9999-9999-9999-999999999999  L-1005   \n",
            "3  sally.williams@global.org  a0b1c2d3-4e5f-6a7b-8c9d-e0f1a2b3c4d5  L-1006   \n",
            "4        mike.davis@corp.com  f8e9d0c1-2b3a-4e5f-b6c7-d8e9f0a1b2c3  L-1007   \n",
            "5     alice.johnson@corp.com  11111111-2222-3333-4444-555555555555  L-1008   \n",
            "6     frank.white@partner.io  9f8e7d6c-5b4a-3e2d-1c0b-9a8f7e6d5c4b  L-1009   \n",
            "7    elena.rodriguez@int.com                                  None  L-1010   \n",
            "\n",
            "  transaction_ids        full_name creation_date  total_sales  \\\n",
            "0         TX-4001         Jane Doe    2024-09-16       145.50   \n",
            "1         TX-4002        Bob Brown    2024-09-18        32.99   \n",
            "2         TX-4004       John Smith    2024-09-19       500.00   \n",
            "3         TX-4005   Sally Williams    2024-09-20       201.15   \n",
            "4         TX-4007       Mike Davis    2024-09-21        99.90   \n",
            "5         TX-4008    Alice Johnson    2024-09-22        25.00   \n",
            "6            None      Frank White    2024-09-23         0.00   \n",
            "7            None  Elena Rodriguez    2024-09-24         0.00   \n",
            "\n",
            "   total_transactions  completed_transactions  pending_transactions  \\\n",
            "0                   1                       1                     0   \n",
            "1                   1                       1                     0   \n",
            "2                   1                       1                     0   \n",
            "3                   1                       1                     0   \n",
            "4                   1                       1                     0   \n",
            "5                   1                       0                     1   \n",
            "6                   0                       0                     0   \n",
            "7                   0                       0                     0   \n",
            "\n",
            "   completed_amount  pending_amount  total_page_views       last_activity  \n",
            "0            145.50             0.0                92 2024-09-25 09:00:00  \n",
            "1             32.99             0.0                15 2024-09-24 11:15:00  \n",
            "2            500.00             0.0                 0                 NaT  \n",
            "3            201.15             0.0                22 2024-09-24 14:05:00  \n",
            "4             99.90             0.0               105 2024-09-24 12:45:00  \n",
            "5              0.00            25.0                 0                 NaT  \n",
            "6              0.00             0.0                 1 2024-09-24 16:10:00  \n",
            "7              0.00             0.0                 0                 NaT  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rejection log\n",
        "with open(REJECTED_LOG_FILE, 'r') as f:\n",
        "    print(f.read())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-XtmVLMgXP9",
        "outputId": "1bac9e46-a6d1-41ae-9b5f-34bc84cb8296"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transaction_id|status|amount|reason\n",
            "TX-4003|Refunded|-10.0|Non-positive amount (-10.0)\n",
            "TX-4006|Cancelled|-5.0|Non-positive amount (-5.0)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}